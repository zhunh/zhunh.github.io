---
title: AI笔记
date: 2020-06-12 09:05:43
tags:
- AI
- 机器学习
---

## 1.常用激活函数
- Sigmoid 函数

$$
\sigma (x) = \frac{1}{1+e^{-x}}
$$

- 双曲正切函数
$$
tanhx =\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}
$$

- ReLU函数(Rectified Linear Unit)
$$
relu(x)=max(0,x)
$$

<!--more-->

## 2.归一化

> 归一化特征值，消除属性之间量级不同导致的影响；压缩数据空间

$$
newValue = \frac{oldValue-min}{max-min} 
$$

注：max和min分别为数据集中数据的最大值和最小值。

##3.贝叶斯准则
> 贝叶斯准则告诉我们如何交换条件概率中的条件和结果

$$
p(c|x)=\frac{p(x|c)p(c)}{p(x)}
$$

实际使用：
$$
p(类别|特征)=\frac{p(特征|类别)p(类别)}{p(特征)}
$$
